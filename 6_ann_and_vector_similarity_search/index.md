# 6. 近似最近傍探索とベクトル類似検索

## 0. 準備

以下のエンコーダのexample useを実行できるように環境を整えよ。

> https://tfhub.dev/google/universal-sentence-encoder/4

## 1. ベクトル化

題材のエンコーダを実行して適当なクエリをベクトル化せよ。

## 2. ドット積

題材の製品ごとに、その `product_title` をベクトル化せよ。同時に適当なクエリとの**ドット積**を計算し、それを優先度として上位10件の優先度と `product_title` を表示せよ。

ただし、この処理は非常に重いので、題材の製品を適度にサンプリングして行え（以降の問題でも同じ）。

## 3. ANNライブラリ

適当な**近似最近傍探索**ライブラリ（**ANN**ライブラリ）を入手し、その機能で `2.` を行え。ただし通常ANNライブラリはドット積の降順に対応していないので、例えばコサイン類似度またはユークリッド距離の昇順にしてみよ。

## 4. 代表点

続いて、転置インデックスとの相性が良い**クラスタベースの**近似最近傍探索を実装する。

まず、題材の製品をランダムにサンプリングし、それらにANNライブラリを利用してインデックスを張れ。サンプル数は製品数の平方根とする。

以降、これらのサンプルを**代表点**と呼び、IDを振って区別する。

## 5. インデックス時の引き当て

題材の製品ごとに代表点を1つ引き当て、そのIDを付与せよ。

## 6. クエリ時の引き当て

適当なクエリをベクトル化し、代表点を1つ引き当てよ。
続いて、そのクエリと代表点のIDを共有する製品群についてのみドット積を計算し、それを優先度として上位10件の優先度と `product_title` を表示せよ。

## 7. 簡易的な評価

題材の製品をランダムにサンプリングし、それらの `product_title` をクエリとして `6.` を行え。
このとき元の製品そのもの、または同じ `product_title` の製品が最高の優先度を獲得するのが理想と考えられる。そうなった割合を求めよ。

## 8. パラメータチューニング

ここで実装したクラスタベースの近似最近傍探索には、以下の通り多くのパラメータがあった。

- 用意する代表点の数
- 製品に対して引き当てる代表点の数
- クエリに対して引き当てる代表点の数

これらを何通りかチューニングし、その都度 `4.` から `7.` を行え。ただし `7.` において評価値と実行時間のトレードオフがあると考えられるので、このとき実行時間も測定せよ。

## 9. クラスタリング

より適切な代表点の選び方もあると考えられる。
題材の製品をクラスタリングし、各クラスタの平均ベクトルを代表点として `5.` から `7.` を行え。
